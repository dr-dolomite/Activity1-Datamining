{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"100\">**Import Dependencies**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"100\">**Load the dataset then check & drop nulls**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsv(path):\n",
    "    # Error handling for loading CSV files\n",
    "    try:\n",
    "        # Loads CSV files as pandas framework\n",
    "        data = pd.read_csv(path)\n",
    "        # Checks and drops all null values\n",
    "        if data.isnull().sum().any():\n",
    "            if data.empty == True:\n",
    "                data = data.dropna()\n",
    "                print(\"Dataset loaded. Nulls dropped.\" \"\\n\")\n",
    "        else:\n",
    "            print(\"Dataset loaded. No null.\" \"\\n\")    \n",
    "    except:\n",
    "        print('There is an Error!')\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"120\">**Changing the needed values to new values**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadCsv('./Iris.csv')\n",
    "# Drops Id column from database\n",
    "data = data.drop(['Id'], axis=1)\n",
    "# Adds two new columns with designated values\n",
    "data['sepalLengthInput'] = 5.5\n",
    "data['sepalWidthInput'] = 5\n",
    "data['sepalWidthInput'] = data['sepalWidthInput'].astype(float)\n",
    "# Change the value of the given columns\n",
    "#oldValue = 5.5\n",
    "#newValue = 4.2\n",
    "#data.loc[data['SepalLengthCm'] == oldValue, 'SepalLengthCm'] = newValue\n",
    "data['Species'] = data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2])\n",
    "# Rearrange columns\n",
    "#data = data[['Species', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"120\">**Euclidean Distance Formula**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EuclideanDistance function\n",
    "def EuclideanDistance(train_data, test_data):\n",
    "    test_data['EuclideanDistance'] = np.sqrt((train_data['SepalLengthCm'] - test_data['sepalLengthInput'])**2 + (train_data['SepalWidthCm'] - test_data['sepalWidthInput'])**2)\n",
    "    test_data = test_data.sort_values(by='EuclideanDistance')\n",
    "    return test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"120\">**KNN with Confusion Matrix & Class Representation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Calculate the Euclidean distance for each data point in the test dataset\n",
    "test_data = EuclideanDistance(train_data, test_data)\n",
    "# Implement the KNN algorithm\n",
    "def KNN(k, test_data):\n",
    "    return test_data.head(k)['Species'].mode()[0]\n",
    "# Make predictions for the test data\n",
    "predictions = []\n",
    "for i in range(len(test_data)):\n",
    "    predictions.append(KNN(5, test_data.iloc[i:i+1]))\n",
    "\n",
    "accuracy = accuracy_score(test_data['Species'], predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_data['Species'], predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the classification report\n",
    "class_report = classification_report(test_data['Species'], predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"120\">**Manhattan Distance**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ManhattanDistance(data):\n",
    "    # Manhattan distance (not sure if correct)\n",
    "    # Define the new data point\n",
    "    new_data_point = [5, 3, 4, 2]\n",
    "    # Calculate the absolute difference between each data point and the new data point\n",
    "    abs_differences = np.abs(data.iloc[:, :4] - new_data_point)\n",
    "    # Find the sum of the absolute differences\n",
    "    manhattan_distance = abs_differences.sum(axis=1)\n",
    "    # Add the Manhattan distance to the DataFrame\n",
    "    data[\"ManhattanDistance\"] = manhattan_distance\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNManhattan(data):\n",
    "    # Define the number of nearest neighbors to find (k)\n",
    "    k = 5\n",
    "    # Sort the DataFrame by the Manhattan distance\n",
    "    data = data.sort_values(\"ManhattanDistance\")\n",
    "    # Find the k nearest neighbors\n",
    "    neighbors = data.iloc[:k, :]\n",
    "    # Get the most common species among the k nearest neighbors\n",
    "    prediction = neighbors[\"Species\"].value_counts().index[0]\n",
    "    # Print the prediction\n",
    "    print(\"Predicted species:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleanedData(data)\n",
    "data = ManhattanDistance(data)\n",
    "KNNManhattan(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IrisKNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efff00b816737a71a10b8ed1bea04b391c47a14db3708d4f29e165e593b40c46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
